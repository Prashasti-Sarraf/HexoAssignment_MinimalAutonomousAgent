# -*- coding: utf-8 -*-
"""minimal_autonomous_agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q65F4NF3sTSzX6heFcJNximkLLRFgrEa
"""

"""
Minimal Autonomous Agent for MLEbench-lite datasets

ONE-LINER:
python minimal_autonomous_agent.py --dataset_dir <path> --output submission.csv --seeds 0 1 2 --time_limit 86400
"""

import os
import json
import time
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# -----------------------------
# Sklearn models
# -----------------------------
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

# -------------------------------
# For image/timeseries pipelines
# -------------------------------
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    import torchvision.models as models
    from torch.utils.data import DataLoader, Dataset
    from PIL import Image
    import librosa
    import librosa.display
except ImportError:
    torch = None
    print("Torch not installed. Image/Timeseries pipelines will be disabled.")



# -----------------------------
# Logging helper
# -----------------------------
def log(msg, logfile):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{ts}] {msg}"
    print(line)
    with open(logfile, "a") as f:
        f.write(line + "\n")

# -----------------------------
# Column detection for text/tabular
# -----------------------------
def get_text_and_label_cols(df):
    if "text" in df.columns and "author" in df.columns:
        return "text", "author"

    object_cols = [c for c in df.columns if df[c].dtype == "object"]
    if object_cols:
        text_col = max(object_cols, key=lambda c: df[c].astype(str).str.len().mean())
    else:
        text_col = df.columns[0]

    for c in df.columns:
        if c.lower() in ("label", "target", "class"):
            return text_col, c

    candidate = None
    for c in df.columns:
        if c != text_col and df[c].nunique() <= 10:
            candidate = c
            break

    if candidate is None:
        candidate = df.columns[-1]

    return text_col, candidate

# -----------------------------
# Modality detection
# -----------------------------

def detect_modality(dataset_dir):
    p = Path(dataset_dir)

    # collect all CSVs
    csvs = list(p.glob("*.csv")) + list(p.rglob("*.csv"))

    found_before = False
    found_after = False

    for c in csvs:
        try:
            df = pd.read_csv(c, nrows=50)
        except:
            continue

        cols = set(df.columns)

        if "before" in cols:
            found_before = True
        if "after" in cols:
            found_after = True

        # SEQ2SEQ → "before" AND "after"
        if {"before", "after"} <= cols:
            return "text-seq2seq"

    # If anywhere 'before' appears alone → still text (test.csv)
    if found_before:
        return "text"

    # TABULAR detection
    if csvs:
        df = pd.read_csv(csvs[0], nrows=200)
        object_cols = df.select_dtypes(include=["object"]).columns

        # heuristic: many long text columns → text classification
        text_like = 0
        for col in object_cols:
            s = df[col].astype(str)
            if s.apply(len).mean() > 20:
                text_like += 1

        if text_like > 0:
            return "text"
        return "tabular"

    # Images
    image_files = list(p.rglob("*.png")) + list(p.rglob("*.jpg"))
    if image_files:
        return "image"

    # Timeseries
    audio_files = list(p.rglob("*.aif")) + list(p.rglob("*.wav")) + list(p.rglob("*.mp3"))
    if audio_files:
         return "timeseries"

    return "unknown"

# -----------------------------
# Text pipeline
# -----------------------------
def run_text(dataset_dir, output_path, seed, logfile):
    p = Path(dataset_dir)
    train_csv = next((f for f in p.glob("train.csv")), None)
    test_csv = next((f for f in p.glob("test.csv")), None)

    if train_csv is None:
        log("No train.csv found", logfile)
        return None

    log(f"Reading train.csv:{train_csv}", logfile)
    df = pd.read_csv(train_csv)
    log(f"First 5 rows:{df.head()}", logfile)

    text_col, label_col = get_text_and_label_cols(df)
    log(f"Using text_col={text_col}, label_col={label_col}", logfile)

    y = df[label_col]
    X = df[text_col].astype(str)

    if y.nunique() < 2:
        log("Dataset contains <2 classes. Skipping.", logfile)
        return None

    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=seed, stratify=y
    )

    vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1, 2))
    X_train_vec = vectorizer.fit_transform(X_train)
    X_val_vec = vectorizer.transform(X_val)

    clf = LogisticRegression(max_iter=200, n_jobs=-1)
    clf.fit(X_train_vec, y_train)

    pred = clf.predict(X_val_vec)
    acc = accuracy_score(y_val, pred)
    log(f"Seed {seed}: val accuracy = {acc:.4f}", logfile)

    if seed == 0 and test_csv is not None:
        test_df = pd.read_csv(test_csv)
        test_X = test_df[text_col].astype(str)
        test_vec = vectorizer.transform(test_X)
        test_pred = clf.predict(test_vec)

        sub = pd.DataFrame({
            "id": test_df["id"] if "id" in test_df.columns else np.arange(len(test_df)),
            label_col: test_pred
        })
        sub.to_csv(output_path, index=False)
        log(f"Wrote submission.csv ({len(sub)} rows)", logfile)

    return acc

# -----------------------------
# Tabular pipeline
# -----------------------------

def run_tabular(dataset_dir, output_path, seed, logfile):
    import pandas as pd
    import numpy as np
    from pathlib import Path
    from sklearn.model_selection import train_test_split
    from sklearn.impute import SimpleImputer
    from lightgbm import LGBMClassifier

    p = Path(dataset_dir)

    # -----------------------------------------------------
    # Load train.csv
    # -----------------------------------------------------
    train_csv = p / "train.csv"
    if not train_csv.exists():
        log("No train.csv found", logfile)
        return None

    df = pd.read_csv(train_csv)
    log(f"Loaded train.csv shape = {df.shape}", logfile)

    # -----------------------------------------------------
    # Detect label column
    # -----------------------------------------------------
    label_candidates = ["target", "label", "class", "y"]
    label_col = next((c for c in label_candidates if c in df.columns), df.columns[-1])

    X = df.drop(columns=[label_col])
    y = df[label_col]

    # -----------------------------------------------------
    # Try numeric conversion for object columns
    # -----------------------------------------------------
    for col in X.columns:
        if X[col].dtype == "object":
            conv = pd.to_numeric(X[col], errors="coerce")
            if conv.notna().mean() > 0.9:
                X[col] = conv

    # -----------------------------------------------------
    # Column type split
    # -----------------------------------------------------
    numeric_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]
    categorical_cols = [c for c in X.columns if c not in numeric_cols]

    # -----------------------------------------------------
    # Imputers
    # -----------------------------------------------------
    num_imp = SimpleImputer(strategy="mean")
    cat_imp = SimpleImputer(strategy="most_frequent")

    X[numeric_cols] = num_imp.fit_transform(X[numeric_cols])
    X[categorical_cols] = cat_imp.fit_transform(X[categorical_cols])

    for c in categorical_cols:
        X[c] = X[c].astype("category")

    # -----------------------------------------------------
    # Train/Val split
    # -----------------------------------------------------
    strat = y if len(np.unique(y)) > 1 else None  # avoid stratify error
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=seed, stratify=strat
    )

    # -----------------------------------------------------
    # LightGBM Model
    # -----------------------------------------------------
    model = LGBMClassifier(
        n_estimators=300,
        learning_rate=0.03,
        num_leaves=64,
        n_jobs=-1,
        random_state=seed,
    )

    model.fit(X_train, y_train)

    val_acc = model.score(X_val, y_val)
    log(f"Seed {seed}: val accuracy = {val_acc:.4f}", logfile)

    # -----------------------------------------------------
    # Inference → submission.csv
    # -----------------------------------------------------
    test_csv = p / "test.csv"
    if test_csv.exists():
        df_test = pd.read_csv(test_csv)

        # Match missing columns
        for col in X.columns:
            if col not in df_test.columns:
                df_test[col] = np.nan

        # Ensure order is same as training
        df_test = df_test[X.columns]

        # Apply imputers
        df_test[numeric_cols] = num_imp.transform(df_test[numeric_cols])
        df_test[categorical_cols] = cat_imp.transform(df_test[categorical_cols])

        for c in categorical_cols:
            df_test[c] = df_test[c].astype("category")

        preds = model.predict(df_test)

        # Use id column if present
        if "id" in df_test.columns:
            submission = pd.DataFrame({"id": df_test["id"], label_col: preds})
        else:
            submission = pd.DataFrame({label_col: preds})

        submission.to_csv(output_path, index=False)
        log(f"Saved submission to {output_path}", logfile)
    else:
        log("No test.csv found → skipping submission generation", logfile)

    return val_acc


# ---------------------------------------------------------
# Seq2Seq Text Normalization
# ---------------------------------------------------------
def run_text_seq2seq(dataset_dir, output_path, seed, logfile):
    import pandas as pd
    import numpy as np
    import time
    import re
    from pathlib import Path

    def log(msg):
        with open(logfile, "a") as f:
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {msg}\n")

    p = Path(dataset_dir)
    all_csvs = list(p.glob("*.csv")) + list(p.rglob("*.csv"))
    train_csv = None
    test_csv = None

    # Identify train/test CSVs
    for c in all_csvs:
        try:
            dfp = pd.read_csv(c, nrows=5)
        except:
            continue
        cols = set(dfp.columns)
        if {"before", "after"} <= cols:
            train_csv = c
        elif "before" in cols:
            test_csv = c

    if train_csv is None:
        log("Seq2Seq: train CSV not found.", logfile)
        return None

    # -----------------------
    # Load train CSV
    # -----------------------
    df = pd.read_csv(train_csv, dtype=str).dropna()
    df["before"] = df["before"].astype(str)
    df["after"] = df["after"].astype(str)

    # -----------------------
    # Train/val split
    # -----------------------
    val_df = df.sample(min(5000, len(df)), random_state=seed)
    train_df = df.drop(val_df.index)

    # ---------------------------------------------------------
    # Smart normalization function (can use GRU/T5/Transformer)
    # ---------------------------------------------------------
    def normalize_text(s):
        s = s.lower().strip()                     # lowercase & strip
        s = re.sub(r"\s+", " ", s)                # collapse multiple spaces
        s = re.sub(r"([.,!?;:])\1+", r"\1", s)    # remove repeated punctuation
        s = re.sub(r"\d+", "<num>", s)            # normalize digits
        # Simple SMS-style substitutions
        s = re.sub(r"\bu\b", "you", s)
        s = re.sub(r"\br\b", "are", s)
        s = re.sub(r"\bpls\b", "please", s)
        s = re.sub(r"\bthx\b", "thanks", s)
        return s

    # -----------------------
    # Validation Exact-Match
    # -----------------------
    correct, total = 0, 0
    for b, a in zip(val_df["before"], val_df["after"]):
        if normalize_text(b) == a:
            correct += 1
        total += 1
    acc = correct / total if total else 0
    log(f"Validation Exact-Match: {acc:.4f}")

    # -----------------------
    # Test predictions
    # -----------------------
    if test_csv is not None:
        dft = pd.read_csv(test_csv, dtype=str)
        dft["after"] = dft["before"].astype(str).apply(normalize_text)
        dft.to_csv(output_path, index=False)
        log(f"Saved predictions to {output_path}")

    return acc




# -----------------------------
# Image pipeline
# -----------------------------

def run_image(dataset_dir, output_path, seed, logfile):
    if torch is None:
        log("Torch not installed → image pipeline disabled.", logfile)
        return None

    p = Path(dataset_dir)
    train_csv = p / "train.csv"
    test_csv = p / "test.csv"

    if not train_csv.exists():
        log("No train.csv found", logfile)
        return None

    # -----------------------------
    # Load CSVs
    # -----------------------------
    df = pd.read_csv(train_csv)
    log(f"Loaded train.csv shape={df.shape}", logfile)

    if 'image_name' not in df.columns or 'target' not in df.columns:
        log("Expected columns 'image_name' and 'target' not found.", logfile)
        return None

    # Train/val split
    X_train_df, X_val_df = train_test_split(
        df, test_size=0.2, random_state=seed, stratify=df['target']
    )

    # -----------------------------
    # Dataset class
    # -----------------------------
    class MDataset(torch.utils.data.Dataset):
        def __init__(self, df, img_dir, transform=None, is_test=False):
            self.df = df
            self.img_dir = Path(img_dir)
            self.transform = transform
            self.is_test = is_test

        def __len__(self):
            return len(self.df)

        def __getitem__(self, idx):
            img_name = str(self.df.iloc[idx]['image_name'])
            img_path = self.img_dir / img_name
            image = Image.open(img_path).convert("RGB")
            if self.transform:
                image = self.transform(image)
            if self.is_test:
                return image, img_name
            label = self.df.iloc[idx]['target']
            return image, torch.tensor(label, dtype=torch.float32)

    # -----------------------------
    # Transforms
    # -----------------------------
    train_transform = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
    ])
    val_transform = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
    ])

    # -----------------------------
    # Datasets & loaders
    # -----------------------------
    train_dataset = MDataset(X_train_df, p/'train', transform=train_transform)
    val_dataset = MDataset(X_val_df, p/'train', transform=val_transform)

    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # -----------------------------
    # Model
    # -----------------------------
    model = models.resnet18(pretrained=True)
    model.fc = nn.Linear(model.fc.in_features, 1)  # binary classification
    model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.BCEWithLogitsLoss()

    # -----------------------------
    # Training loop
    # -----------------------------
    best_acc = 0
    for epoch in range(3):  # small number for demonstration
        model.train()
        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)
            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        # Validation
        model.eval()
        all_preds, all_labels = [], []
        with torch.no_grad():
            for imgs, labels in val_loader:
                imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)
                outputs = torch.sigmoid(model(imgs))
                all_preds.append(outputs.cpu())
                all_labels.append(labels.cpu())
        all_preds = torch.cat(all_preds)
        all_labels = torch.cat(all_labels)
        preds_bin = (all_preds > 0.5).float()
        val_acc = (preds_bin == all_labels).float().mean().item()
        log(f"Epoch {epoch+1}: val accuracy = {val_acc:.4f}", logfile)

    # -----------------------------
    # Test predictions
    # -----------------------------
    if test_csv.exists():
        df_test = pd.read_csv(test_csv)
        test_dataset = MDataset(df_test, p/'test', transform=val_transform, is_test=True)
        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)

        model.eval()
        preds_list, ids_list = [], []
        with torch.no_grad():
            for imgs, img_names in test_loader:
                imgs = imgs.to(device)
                outputs = torch.sigmoid(model(imgs))
                preds_list.extend((outputs.cpu() > 0.5).int().numpy().flatten())
                ids_list.extend(img_names)

        submission = pd.DataFrame({"id": ids_list, "target": preds_list})
        submission.to_csv(output_path, index=False)
        log(f"Saved submission to {output_path}", logfile)

    return val_acc



# -----------------------------
# Timeseries pipeline
# -----------------------------
def run_timeseries(dataset_dir, output_path, seed, logfile):
    log("Running time-series audio pipeline...", logfile)

    p = Path(dataset_dir)

    # audio files
    train_files = list(p.rglob("*_0.aif")) + list(p.rglob("*_1.aif"))
    test_files = list(p.rglob("*.aif"))
    test_files = [f for f in test_files if not f.name.endswith("_0.aif") and not f.name.endswith("_1.aif")]

    if len(train_files) == 0:
        log("No .aif training audio found.", logfile)
        return None

    # --------------- Dataset ---------------
    class AudioDataset(Dataset):
        def __init__(self, files, is_test=False):
            self.files = files
            self.is_test = is_test

        def __len__(self):
            return len(self.files)

        def __getitem__(self, idx):
            file = self.files[idx]
            y, sr = librosa.load(file, sr=32000)

            # mel spectrogram
            mel = librosa.feature.melspectrogram(
                y=y,
                sr=sr,
                n_fft=1024,
                hop_length=512,
                n_mels=64
            )
            mel = librosa.power_to_db(mel).astype(np.float32)
            mel = torch.tensor(mel).unsqueeze(0)  # 1 × Mel × Time

            if self.is_test:
                return mel, file.name

            label = 1 if file.name.endswith("_1.aif") else 0
            return mel, torch.tensor(label, dtype=torch.float32)

    # --------------- CNN Model ---------------
    class SimpleCNN(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = nn.Sequential(
                nn.Conv2d(1, 8, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(8, 16, 3, padding=1),
                nn.ReLU(),
                nn.AdaptiveAvgPool2d((1, 1)),
            )
            self.fc = nn.Linear(16, 1)

        def forward(self, x):
            x = self.conv(x)
            x = x.view(x.size(0), -1)
            return self.fc(x)

    # --------------- Train/Val Split ---------------
    rng = np.random.default_rng(seed)
    train_idx = rng.choice(len(train_files), int(0.8 * len(train_files)), replace=False)
    val_idx = [i for i in range(len(train_files)) if i not in train_idx]

    train_set = AudioDataset([train_files[i] for i in train_idx])
    val_set = AudioDataset([train_files[i] for i in val_idx])

    train_loader = DataLoader(train_set, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=8, shuffle=False)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    model = SimpleCNN().to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    # --------------- Training ---------------
    for epoch in range(3):  # tiny for Kaggle time limits
        model.train()
        for X, y in train_loader:
            X, y = X.to(device), y.to(device).unsqueeze(1)
            optimizer.zero_grad()
            out = model(X)
            loss = criterion(out, y)
            loss.backward()
            optimizer.step()

        # validation
        model.eval()
        preds, labels = [], []
        with torch.no_grad():
            for X, y in val_loader:
                X = X.to(device)
                pr = torch.sigmoid(model(X)).cpu()
                preds.append(pr)
                labels.append(y.unsqueeze(1))
        preds = torch.cat(preds)
        labels = torch.cat(labels)
        val_acc = ( (preds > 0.5).float() == labels ).float().mean().item()

        log(f"Epoch {epoch+1}: val accuracy = {val_acc:.4f}", logfile)

    # --------------- Test Predictions ---------------
    if len(test_files) > 0:
        test_set = AudioDataset(test_files, is_test=True)
        test_loader = DataLoader(test_set, batch_size=8, shuffle=False)

        model.eval()
        ids, out_list = [], []
        with torch.no_grad():
            for X, names in test_loader:
                X = X.to(device)
                pr = torch.sigmoid(model(X)).cpu().numpy().flatten()
                ids.extend(names)
                out_list.extend(pr)

        submission = pd.DataFrame({"id": ids, "target": out_list})
        submission.to_csv(output_path, index=False)
        log(f"Saved submission to {output_path}", logfile)

    return val_acc


# -----------------------------
# Unified pipeline dispatcher
# -----------------------------
def run_pipeline(dataset_dir, output_path, seed, logfile, modality):
    if modality == "text":
        return run_text(dataset_dir, output_path, seed, logfile)

    elif modality == "text-seq2seq":
        log("Running Seq2Seq text normalization...", logfile)

        score = run_text_seq2seq(dataset_dir, output_path, seed, logfile)

        # write metric json (per-seed result)
        metrics_path = Path(output_path).with_name("metrics.json")
        with open(metrics_path, "w") as f:
            json.dump({"exact_match": score}, f)

        log(f"Seq2Seq finished. Exact Match: {score}", logfile)
        return score   # <-- FIXED
        # score:.4f

    elif modality == "tabular":
        return run_tabular(dataset_dir, output_path, seed, logfile)

    elif modality == "image":
        return run_image(dataset_dir, output_path, seed, logfile)

    elif modality == "timeseries":
        return run_timeseries(dataset_dir, output_path, seed, logfile)

    else:
        log(f"Unknown modality. Skipping.", logfile)
        return None

# -----------------------------
# Main agent
# -----------------------------
def run_agent(dataset_dir, output_path, seeds, time_limit):
    logfile = "run_log.txt"
    with open(logfile, "w") as f:
        f.write("")

    modality = detect_modality(dataset_dir)
    log(f"Detected modality: {modality}", logfile)

    accs = []
    start = time.time()
    for s in seeds:
        if time.time() - start > time_limit:
            log("Time limit exceeded.", logfile)
            break
        acc = run_pipeline(dataset_dir, output_path, s, logfile, modality)
        if acc is not None:
            accs.append(acc)

    if len(accs) == 0:
        log("No valid seeds produced metrics.", logfile)
        return

    mean = float(np.mean(accs))
    se = float(np.std(accs, ddof=1) / np.sqrt(len(accs)))
    mean_pct = mean * 100
    se_pct = se * 100
    medal = f"{mean_pct:.2f} ± {se_pct:.2f}"

    log(f"Completed seeds. Mean={mean:.4f}, SE={se:.4f}", logfile)

    with open("metrics.json", "w") as f:
        json.dump({
            "mean": mean,
            "se": se,
            "Any Medal(%)": medal,
            "per_seed": accs
        }, f, indent=2)

    log("Wrote metrics.json and run_log.txt", logfile)

# -----------------------------
# CLI
# -----------------------------
import argparse

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset_dir", type=str, required=True)
    parser.add_argument("--output", type=str, required=True)
    parser.add_argument("--seeds", nargs="+", type=int, default=[0,1,2])
    parser.add_argument("--time_limit", type=int, default=86400)
    args = parser.parse_args()

    run_agent(
        dataset_dir=args.dataset_dir,
        output_path=args.output,
        seeds=args.seeds,
        time_limit=args.time_limit
    )