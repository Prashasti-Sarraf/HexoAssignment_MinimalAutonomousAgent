# -*- coding: utf-8 -*-
"""minimal_autonomous_agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ej3qYnRyQjXV46rK0BHkn8g1yz6JPBFJ
"""

"""
Minimal Autonomous Agent for MLEbench-lite datasets
Single-file agent that: detects modality, trains a simple baseline, and emits submission.csv

ONE-LINER (run this in shell):
python minimal_autonomous_agent.py --dataset_dir /path/to/mlebench/dataset --output submission.csv --seeds 0 1 2 --time_limit 86400

What this file contains:
- An autonomous pipeline that inspects the dataset folder structure and files to infer modality
- Lightweight baseline per modality (tabular/text/image/time-series/multimodal)
- Multi-seed run and basic reporting (mean Â± standard error)
- README (<=200 words) and reasoning trace written to README.md and run_log.txt

Notes: this is intentionally minimal and dependency-light. For image tasks the script uses PyTorch; for tabular/text it uses scikit-learn. If dependencies are missing the script will print instructions.

"""

import argparse
import os
import sys
import json
import time
import math
import random
from pathlib import Path
from collections import Counter

# Lightweight dependency checks
try:
    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import OneHotEncoder, StandardScaler
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
except Exception as e:
    print("Some CPU ML dependencies are missing. Please install: pandas scikit-learn numpy")
    print(e)

# Try optional heavy deps
HAS_TORCH = True
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import Dataset, DataLoader
    from torchvision import transforms
    from PIL import Image
except Exception:
    HAS_TORCH = False

# Utilities

def log(msg, logfile):
    ts = time.strftime('%Y-%m-%d %H:%M:%S')
    line = f"[{ts}] {msg}"
    print(line)
    with open(logfile, 'a') as f:
        f.write(line + "\n")


def detect_modality(dataset_dir):
    p = Path(dataset_dir)
    files = list(p.rglob('*'))
    names = [f.name.lower() for f in files if f.is_file()]
    exts = [f.suffix.lower() for f in files if f.is_file()]

    # Image indicators
    image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    if any(e in image_exts for e in exts):
        # If there's a 'train' directory with image files
        return 'image'

    # Tabular indicator
    if any(n.endswith('.csv') for n in names):
        # read first CSV to check for text-heavy columns
        sample = [str(f) for f in files if f.suffix.lower()=='.csv']
        if not sample:
            return 'tabular'
        try:
            df = pd.read_csv(sample[0], nrows=200)
            # heuristics
            text_cols = [c for c in df.columns if df[c].dtype=='object' and df[c].str.len().mean() > 20]
            if len(text_cols) >= 1:
                return 'text' if len(text_cols) > 0 and len(df.columns) <= 4 else 'tabular'
            # time-series: look for a timestamp column
            timestamp_like = [c for c in df.columns if 'time' in c.lower() or 'date' in c.lower()]
            if timestamp_like:
                return 'timeseries'
        except Exception:
            return 'tabular'

    # fallback
    return 'unknown'

# Simple tabular baseline

def run_tabular(dataset_dir, output_path, seed, logfile):
    # Expect CSV files 'train.csv' and 'test.csv' or any CSV with target column 'target' or 'label'
    p = Path(dataset_dir)
    csvs = list(p.glob('*.csv'))
    if not csvs:
        # try train/test folders
        csvs = list(p.rglob('*.csv'))
    if not csvs:
        raise FileNotFoundError('No CSV found for tabular task')

    # pick train and test heuristically
    train_file = None
    test_file = None
    for f in csvs:
        if 'train' in f.name.lower():
            train_file = f
        if 'test' in f.name.lower():
            test_file = f
    if train_file is None:
        train_file = csvs[0]
    if test_file is None and len(csvs) > 1:
        test_file = csvs[1]

    df = pd.read_csv(train_file)
    if 'target' in df.columns:
        y = df['target']
        X = df.drop(columns=['target'])
    elif 'label' in df.columns:
        y = df['label']
        X = df.drop(columns=['label'])
    else:
        # assume last column is target
        y = df.iloc[:, -1]
        X = df.iloc[:, :-1]

    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y if len(set(y))>1 else None)

    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = X_train.select_dtypes(include=['object','category']).columns.tolist()

    # simple preprocessing pipeline: impute numerics, scale; impute and one-hot cats
    from sklearn.compose import ColumnTransformer
    num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scale', StandardScaler())])
    cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])
    pre = ColumnTransformer(transformers=[('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)])

    clf = RandomForestClassifier(n_estimators=200, random_state=seed, n_jobs=-1)
    pipe = Pipeline([('pre', pre), ('clf', clf)])

    log('Fitting tabular baseline...', logfile)
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_val)
    acc = accuracy_score(y_val, y_pred)
    log(f'Tabular val accuracy: {acc:.4f}', logfile)

    # Predict on test if available
    if test_file is not None:
        df_test = pd.read_csv(test_file)
        test_ids = df_test.iloc[:, 0] if df_test.shape[1] > 1 else df_test.index
        X_test = df_test.drop(columns=[df_test.columns[0]]) if df_test.shape[1] > 1 else df_test
        preds = pipe.predict(X_test)
        out = pd.DataFrame({'id': test_ids, 'prediction': preds})
    else:
        # no test file: output validation predictions as submission (for demo)
        out = pd.DataFrame({'id': X_val.index, 'prediction': y_pred})

    out.to_csv(output_path, index=False)
    return acc

# Simple text baseline

def run_text(dataset_dir, output_path, seed, logfile):
    p = Path(dataset_dir)
    csvs = list(p.glob('*.csv'))
    if not csvs:
        csvs = list(p.rglob('*.csv'))
    if not csvs:
        raise FileNotFoundError('No CSV found for text task')
    df = pd.read_csv(csvs[0])
    # heuristics: choose text column and label column
    text_col = None
    label_col = None
    for c in df.columns:
        if df[c].dtype=='object' and df[c].str.len().mean() > 5:
            text_col = c
            break
    for c in df.columns:
        if c.lower() in ('label','target','author') or df[c].dtype in (int, float):
            label_col = c
            break
    if text_col is None or label_col is None:
        # fallback: assume first col text, last col label
        text_col = df.columns[0]
        label_col = df.columns[-1]

    X = df[text_col].fillna('')
    y = df[label_col]
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y if len(set(y))>1 else None)

    pipe = Pipeline([('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1,2))), ('clf', LogisticRegression(max_iter=200))])
    log('Fitting text baseline...', logfile)
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_val)
    acc = accuracy_score(y_val, y_pred)
    log(f'Text val accuracy: {acc:.4f}', logfile)

    # test/predict
    # if there's a test.csv, predict; else output val predictions
    test_csv = None
    for f in csvs:
        if 'test' in f.name.lower():
            test_csv = f
            break
    if test_csv:
        df_test = pd.read_csv(test_csv)
        test_ids = df_test.iloc[:,0] if df_test.shape[1]>1 else df_test.index
        X_test = df_test[text_col] if text_col in df_test.columns else df_test.iloc[:,0]
        preds = pipe.predict(X_test.fillna(''))
        out = pd.DataFrame({'id': test_ids, 'prediction': preds})
    else:
        out = pd.DataFrame({'id': X_val.index, 'prediction': y_pred})
    out.to_csv(output_path, index=False)
    return acc

# Minimal image baseline (small CNN) if torch available

def run_image(dataset_dir, output_path, seed, logfile, epochs=5, batch_size=32):
    if not HAS_TORCH:
        raise RuntimeError('PyTorch not available for image baseline')
    p = Path(dataset_dir)
    # Expect train/labels.csv or train folder with subfolders per class
    train_dir = p / 'train'
    test_dir = p / 'test'
    label_csv = None
    for f in p.glob('*.csv'):
        if 'label' in f.name.lower() or 'train' in f.name.lower():
            label_csv = f
            break
    # Simple folder-based loader
    class ImageFolderDataset(Dataset):
        def __init__(self, files, labels, transform=None):
            self.files = files
            self.labels = labels
            self.transform = transform
        def __len__(self):
            return len(self.files)
        def __getitem__(self, idx):
            img = Image.open(self.files[idx]).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img, self.labels[idx]

    transforms_basic = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])

    # Build simple file list and labels
    files = []
    labels = []
    if train_dir.exists():
        # check subfolders
        subfolders = [d for d in train_dir.iterdir() if d.is_dir()]
        if subfolders:
            for i, sf in enumerate(sorted(subfolders)):
                for imgf in sf.rglob('*'):
                    if imgf.suffix.lower() in ('.jpg','.jpeg','.png'):
                        files.append(str(imgf))
                        labels.append(i)
        else:
            # maybe train_dir contains images + labels csv
            if label_csv:
                df = pd.read_csv(label_csv)
                for _, row in df.iterrows():
                    files.append(str(p / row['image']))
                    labels.append(row['label'])
    else:
        # fallback: find images anywhere
        for imgf in p.rglob('*'):
            if imgf.suffix.lower() in ('.jpg','.jpeg','.png'):
                files.append(str(imgf))
                labels.append(0)

    if not files:
        raise FileNotFoundError('No image files found')

    # split
    idx = list(range(len(files)))
    random.Random(seed).shuffle(idx)
    split = int(len(idx)*0.8)
    train_idx = idx[:split]
    val_idx = idx[split:]
    train_files = [files[i] for i in train_idx]
    train_labels = [labels[i] for i in train_idx]
    val_files = [files[i] for i in val_idx]
    val_labels = [labels[i] for i in val_idx]

    train_ds = ImageFolderDataset(train_files, train_labels, transform=transforms_basic)
    val_ds = ImageFolderDataset(val_files, val_labels, transform=transforms_basic)
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    class TinyCNN(nn.Module):
        def __init__(self, out_dim):
            super().__init__()
            self.net = nn.Sequential(
                nn.Conv2d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),
                nn.Conv2d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),
                nn.Flatten(), nn.Linear(32*16*16, 128), nn.ReLU(), nn.Linear(128, out_dim)
            )
        def forward(self,x):
            return self.net(x)

    n_classes = len(set(labels))
    model = TinyCNN(n_classes).to(device)
    opt = optim.Adam(model.parameters(), lr=1e-3)
    loss_fn = nn.CrossEntropyLoss()

    log('Training tiny CNN...', logfile)
    for ep in range(epochs):
        model.train()
        for xb, yb in train_loader:
            xb = xb.to(device)
            yb = torch.tensor(yb, dtype=torch.long, device=device)
            opt.zero_grad()
            out = model(xb)
            loss = loss_fn(out, yb)
            loss.backward()
            opt.step()
        # val
        model.eval()
        allp = []
        ally = []
        with torch.no_grad():
            for xb, yb in val_loader:
                xb = xb.to(device)
                out = model(xb)
                preds = out.argmax(dim=1).cpu().numpy().tolist()
                allp.extend(preds)
                ally.extend(yb)
        acc = accuracy_score(ally, allp)
        log(f'Epoch {ep+1}/{epochs} val acc: {acc:.4f}', logfile)

    # Create a dummy submission from val set
    out = pd.DataFrame({'id': list(range(len(val_files))), 'prediction': allp})
    out.to_csv(output_path, index=False)
    return acc

# Orchestrator

def run_agent(dataset_dir, output_path, seeds, time_limit):
    logfile = 'run_log.txt'
    if os.path.exists(logfile):
        os.remove(logfile)
    start = time.time()
    md = detect_modality(dataset_dir)
    log(f'Detected modality: {md}', logfile)

    scores = []
    for seed in seeds:
        if time.time() - start > time_limit:
            log('Time limit exceeded, stopping.', logfile)
            break
        try:
            if md == 'tabular':
                s = run_tabular(dataset_dir, output_path, seed, logfile)
            elif md == 'text':
                s = run_text(dataset_dir, output_path, seed, logfile)
            elif md == 'image':
                s = run_image(dataset_dir, output_path, seed, logfile)
            else:
                log('Modality unknown - attempting tabular fallback', logfile)
                s = run_tabular(dataset_dir, output_path, seed, logfile)
            scores.append(s)
        except Exception as e:
            log(f'Error on seed {seed}: {e}', logfile)

    # report
    if scores:
        mean = float(np.mean(scores))
        se = float(np.std(scores, ddof=1)/math.sqrt(len(scores))) if len(scores) > 1 else 0.0
        summary = {'mean': mean, 'se': se, 'per_seed': scores}
        with open('metrics.json', 'w') as f:
            json.dump(summary, f, indent=2)
        log(f'Completed seeds. Mean: {mean:.4f}, SE: {se:.4f}', logfile)
    else:
        log('No successful runs completed.', logfile)

     # write README and reasoning trace

  # write README and reasoning trace
    README = """
  Agent README (<=200 words):
This autonomous agent detects dataset modality by inspecting files and runs a lightweight, robust baseline for that modality. For tabular data it uses simple imputation + RandomForest; for text it uses TF-IDF + Logistic Regression; for images it trains a tiny CNN on 64x64 inputs. The strategy emphasizes reliability and low hyperparameter sensitivity so it generalizes across MLEbench tasks. Self-improvement: add automated model selection (AutoML), resource-aware hyperparameter search, pretrained vision/text encoders, and curriculum learning. The agent logs decisions and seeds to allow reproducibility.
"""
    with open('README.md','w') as f:
         f.write(README)
         log('Wrote README.md and run_log.txt', logfile)
    return

# CLI
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset_dir', required=True)
    parser.add_argument('--output', default='submission.csv')
    parser.add_argument('--seeds', nargs='+', type=int, default=[0])
    parser.add_argument('--time_limit', type=int, default=3600)
    args = parser.parse_args()
    run_agent(args.dataset_dir, args.output, args.seeds, args.time_limit)